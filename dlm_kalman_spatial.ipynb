{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.interpolate as interpolate\n",
    "import netCDF4\n",
    "from models.stan_dlm_models import *\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_ce0cf070d48949045c8df5a0c7d92012 NOW.\n"
     ]
    }
   ],
   "source": [
    "# Compile the DLM model: this translates the stan model in stan_dlm_models.py into C++ and compiles it\n",
    "# Note: this step may take a few minutes\n",
    "model_kalman_ar1 = pystan.StanModel(model_code=code_kalman_ar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data \n",
    "# You can do this however you like but the end result must be the following variables loaded in:\n",
    "# N (int) = number of time-steps in the time-series\n",
    "# d float[N] = the data time-series (IMPORTANT: NaNs are NOT allowed, for missing values please set those data to zero and set\n",
    "# the corresponding error for those data points to something very large, like 10^20)\n",
    "# s float[N] = std-deviation error-bars on each data point (set error bars for missing values to a large number; see above)\n",
    "\n",
    "# Import data from a netCDF\n",
    "data = netCDF4.Dataset('data/BASIC_V1_2017_lotus_seascyc_gcsw2017_fac2.nc')\n",
    "\n",
    "# Extract time, pressure and latitude variables from the netCDF\n",
    "T = data['time'][:]\n",
    "P = data['pressure'][:]\n",
    "L = data['latitude'][:]\n",
    "\n",
    "# How many time steps are there? (ie how long is the time-series)\n",
    "N = len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the regressors\n",
    "\n",
    "# Again you can do this however you want, but the result must be the following variables loaded into python\n",
    "# nreg (int) = number of regressors\n",
    "# regressors float[N, nreg] = 2d array with each column representing one regressor over the times corresponding to\n",
    "# the data to be analysed\n",
    "\n",
    "# NOTE: We also mean subtract and rescale all regressors in the same way as for the data so they have dymanic range \n",
    "# of 1 \n",
    "\n",
    "# IMPORTANT: Missing values/NaNs are NOT supported, please interpolate missing values or similar so they are all \n",
    "# real valued\n",
    "\n",
    "# ENSO\n",
    "y = np.loadtxt('regressors/ENSO_MEI_ENSO_1950_201802.dat')\n",
    "t = np.loadtxt('regressors/ENSOTime_MEI_ENSO_1950_201802.dat')\n",
    "y = y - np.mean(y)\n",
    "y = y/(max(y) - min(y))\n",
    "Y = interpolate.InterpolatedUnivariateSpline(t, y)\n",
    "enso = Y(T) # This extacts the regressor at the times you have in your dataset, interpolated in case the time grid is different to the actual data\n",
    "\n",
    "# Solar\n",
    "y = np.loadtxt('regressors/Flux_F30_monthly_195111_201803_absolute.dat')\n",
    "t = np.loadtxt('regressors/Time_F30_monthly_195111_201803_absolute.dat')\n",
    "y = y - np.mean(y)\n",
    "y = y/(max(y) - min(y))\n",
    "Y = interpolate.InterpolatedUnivariateSpline(t, y)\n",
    "solar = Y(T)\n",
    "\n",
    "# QBO30\n",
    "y = np.loadtxt('regressors/multi_qbo30_1953_2018.dat')\n",
    "t = np.loadtxt('regressors/multi_qbotime_1953_2018.dat')\n",
    "y = y - np.mean(y)\n",
    "y = y/(max(y) - min(y))\n",
    "Y = interpolate.InterpolatedUnivariateSpline(t, y)\n",
    "qbo30 = Y(T) \n",
    "\n",
    "# QBO50\n",
    "y = np.loadtxt('regressors/multi_qbo50_1953_2018.dat')\n",
    "t = np.loadtxt('regressors/multi_qbotime_1953_2018.dat')\n",
    "y = y - np.mean(y)\n",
    "y = y/(max(y) - min(y))\n",
    "Y = interpolate.InterpolatedUnivariateSpline(t, y)\n",
    "qbo50 = Y(T) # This extacts the regressor at the times you have in your dataset, interpolated in case the time grid is different\n",
    "\n",
    "# SAOD\n",
    "saod_data = netCDF4.Dataset('regressors/sad_1979_2017_10deg_60S_60N_missNans.nc')\n",
    "# ***RESCALING WILL BE DONE ON THE FLY AS IT IS LATITUDE DEPENDENT***\n",
    "\n",
    "# How many regressors?\n",
    "nreg = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bd61cc7c5a420aa6ea75b1f4debbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='press/lats', max=324), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    }
   ],
   "source": [
    "# How many MCMC chains/samples to do\n",
    "n_chains = 1\n",
    "warmup = 1000\n",
    "iterations = 3000\n",
    "n_samples = n_chains*(iterations-warmup)\n",
    "\n",
    "# Where to save the results\n",
    "trend = np.zeros((n_samples, len(P), len(L), len(T)))\n",
    "slope = np.zeros((n_samples, len(P), len(L), len(T)))\n",
    "seasonal = np.zeros((n_samples, len(P), len(L), len(T)))\n",
    "residuals = np.zeros((n_samples, len(P), len(L), len(T)))\n",
    "regressor_coefficients = np.zeros((n_samples, len(P), len(L), nreg))\n",
    "sigma_trend = np.zeros((n_samples, len(P), len(L)))\n",
    "sigma_seas = np.zeros((n_samples, len(P), len(L)))\n",
    "sigma_AR = np.zeros((n_samples, len(P), len(L)))\n",
    "rho_AR = np.zeros((n_samples, len(P), len(L)))\n",
    "\n",
    "# Set up the progress bar\n",
    "pbar = tqdm.tqdm_notebook(total = len(P)*len(L), desc = \"press/lats\")\n",
    "\n",
    "# Loop over pressures and latitudes\n",
    "for pressure in range(len(P)):\n",
    "    for latitude in range(len(L)):\n",
    "\n",
    "        # Set the data and initialization of parameters that are fed into the DLM\n",
    "\n",
    "        # Pick out a pressure and latitude panel: this is the \"data\" time-series from the netCDF\n",
    "        d = data['o3'][:, pressure, latitude]\n",
    "\n",
    "        # Extract the error-bars on the time-series from the netCDF\n",
    "        s = data['o3_sigma'][:, pressure, latitude]\n",
    "        \n",
    "        # Check if the data are there\n",
    "        if np.mean(d) != 0:\n",
    "\n",
    "            # IMPORTANT: The DLM is set-up to run on mean subtracted data re-scaled to have a dynamic range of unity\n",
    "            # NB: We must re-scale the data here and re-scale back to the original units after the DLM run, look out for this later\n",
    "\n",
    "            # Mean subtract and re-scale the data so it has dynamic range of unity, \n",
    "            # Apply same scaling transform to the std-dev error bars\n",
    "            scale = max(d) - min(d)\n",
    "            mean = np.mean(d)\n",
    "            d = d - mean\n",
    "            d = d/scale\n",
    "            s = s/scale\n",
    "\n",
    "            # Set the SAOD regressor depending on the latitude\n",
    "            y = saod_data['saod_strat_column'][:, latitude]\n",
    "            t = saod_data['time'][:]\n",
    "            y = y - np.mean(y)\n",
    "            y = y/(max(y) - min(y))\n",
    "            Y = interpolate.InterpolatedUnivariateSpline(t, y)\n",
    "            saod = Y(T)\n",
    "\n",
    "            # Regressors\n",
    "            regressors = np.column_stack([enso, solar, qbo30, qbo50, saod]) # Stack of all the regressors together in a 2d array\n",
    "\n",
    "            # Data: this is a dictionary of all of the data/inputs that the DLM model needs (descriptions below)\n",
    "            input_data = {\n",
    "                                'd':d, # float[N] data vector\n",
    "                                's':s, # float[N] std-dev error bars\n",
    "                                'N':N, # (int) number of time-steps in the time-series\n",
    "                                'nreg':nreg, # (int) number of regressors\n",
    "                                'regressors':regressors, # float[N, nreg] the regressors\n",
    "                                'S':10., # prior variance on the regression coefficients (priors are zero mean Gaussian with variance S)\n",
    "                                'sigma_trend_prior':1e-4, # std-dev of the half-Gaussian prior on sigma_trend that controls how wiggly the trend can be\n",
    "                                'sigma_seas_prior':0.01, # std-dev of the half-Gaussian prior on sigma_seas that controls how dynamic the seaonal cycle can be\n",
    "                                'sigma_AR_prior':0.5 # std-dev of the half_Gaussian prior on the AR1 process std-dev \n",
    "                            }\n",
    "\n",
    "            # Initialization: Initial guess values for the hyper-parameters\n",
    "            initial_state = {\n",
    "                             'sigma_trend':0.0001,\n",
    "                             'sigma_seas':0.001,\n",
    "                             'sigma_AR':0.01,\n",
    "                             'rhoAR':0.1,\n",
    "                            }\n",
    "\n",
    "            # Run the model\n",
    "            fit = model_kalman_ar1.sampling(data=input_data, iter=iterations, warmup=warmup, chains=n_chains, init = [initial_state for i in range(n_chains)], verbose=True, pars=('sigma_trend', 'sigma_seas', 'sigma_AR', 'rhoAR', 'trend', 'slope', 'beta', 'seasonal', 'residuals'))\n",
    "\n",
    "            # Extract and re-scale the key bits from the DLM run\n",
    "\n",
    "            # Trend\n",
    "            trend[:, pressure, latitude, :] = fit.extract()['trend'][:,:]*scale + mean\n",
    "\n",
    "            # Gradient of the DLM trend\n",
    "            slope[:, pressure, latitude, :] = fit.extract()['slope'][:,:]*scale\n",
    "\n",
    "            # Seasonal cycle\n",
    "            seasonal[:, pressure, latitude, :] = fit.extract()['seasonal'][:,:]*scale\n",
    "\n",
    "            # Residuals\n",
    "            residuals[:, pressure, latitude, :] = fit.extract()['residuals'][:,:]*scale\n",
    "\n",
    "            # Regressor coefficients (also need re-scaling back to data units)\n",
    "            regressor_coefficients[:, pressure, latitude, :] = fit.extract()['beta'][:,:]*scale\n",
    "\n",
    "            # DLM hyper parameters\n",
    "            sigma_trend[:, pressure, latitude] = fit.extract()['sigma_trend']\n",
    "            sigma_seas[:, pressure, latitude] = fit.extract()['sigma_seas']\n",
    "            sigma_AR[:, pressure, latitude] = fit.extract()['sigma_AR']*scale # Also needs re-scaling back to data units\n",
    "            rho_AR[:, pressure, latitude] = fit.extract()['sigma_AR']\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the results\n",
    "np.save(open('results/trend.npy', 'wb'), trend)\n",
    "np.save(open('results/slope.npy', 'wb'), slope)\n",
    "np.save(open('results/seasonal.npy', 'wb'), seasonal)\n",
    "np.save(open('results/residuals.npy', 'wb'), residuals)\n",
    "np.save(open('results/regressor_coefficients.npy', 'wb'), regressor_coefficients)\n",
    "np.save(open('results/sigma_trend.npy', 'wb'), sigma_trend)\n",
    "np.save(open('results/sigma_seas.npy', 'wb'), sigma_seas)\n",
    "np.save(open('results/sigma_AR.npy', 'wb'), sigma_AR)\n",
    "np.save(open('results/rho_AR.npy', 'wb'), rho_AR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
